# ASPORA PLATFORM ‚Äî 36-Hour Multi-Domain Hackathon Plan

**Winning Hook**: "We didn't build a chatbot. We built a platform where 3 production domains already run ‚Äî with multi-agent orchestration, auto-learning from mistakes, and 85% cost reduction."

---

## The Strategic Shift: From Demo to Production Platform

**OLD PLAN** (Single Demo): Build one ECM workflow from scratch ‚Üí 36 hours of building

**NEW PLAN** (Multi-Domain Platform): Onboard 3 EXISTING production domains ‚Üí 36 hours of integration

**Why This Wins**:
- ‚úÖ **Real skills, not toy examples** ‚Äî DetectingFinCrime, FraudGuardian (TRM), ECM Operations
- ‚úÖ **Production-proven** ‚Äî ECM already runs 1,250 executions/day
- ‚úÖ **Platform story** ‚Äî Shows skill marketplace works (3 domains = 3 independent "app stores")
- ‚úÖ **Competitive moat** ‚Äî Judges see depth (multi-domain) vs breadth (single demo)

---

## Skill Inventory (What We Already Have)

### Domain 1: ECM Operations (9 skills)
**Location**: `/Users/apple/code/aspora/ai-velocity/work-plugins/ecm-operations/`

| Role | Skills | Purpose | Model |
|------|--------|---------|-------|
| **Manager** (5) | triage-and-assign, escalate-stuck-orders, load-balancing, pattern-intelligence, daily-summary | Batch triage, prioritization, assignment | Sonnet 4.5 |
| **Field** (4) | my-tickets, order-details, resolve-ticket, check-runbook | Interactive execution, diagnostics | Haiku 4.5 |

**Key Feature**: Multi-agent orchestration (Manager ‚Üí Field handoff)

### Domain 2: FinCrime Alerts (1 mega-skill)
**Location**: `/Users/apple/Downloads/detecting-fincrime-alerts/`

| Skill | Purpose | Complexity |
|-------|---------|-----------|
| **detecting-fincrime-alerts** | Triages 22 TRM rule types, investigates suspicious transactions, cross-user analysis, disposition (Approve/Hold/Escalate/Reject) | 400-line skill with multi-phase workflow |

**Key Feature**: Regulatory audit-grade investigation (compliance moat)

### Domain 3: Fraud Guardian / TRM Platform (4 skills)
**Location**: `/Users/apple/code/experimentation/trm-platform/`

| Skill | Purpose | Type |
|-------|---------|------|
| **rule-simulation** | Test fraud rules on historical data, measure efficiency before deployment | Simulation |
| **rule-comparison** | Compare old vs new rules, produce truth matrix | Analysis |
| **rule-noise-analysis** | Diagnose why rules are noisy, dimensional breakdown | Analysis |
| **qa-agent** | Verify code runs without errors after changes | QA |

**Key Feature**: Fine-tune fraud rules with data-driven feedback (reduces false positives by 40%)

---

## Total Platform Value

| Metric | Count | Demo Impact |
|--------|-------|-------------|
| **Production Domains** | 3 | "This isn't a hackathon toy" |
| **Total Skills** | 14 | "Skill marketplace has depth" |
| **Multi-Agent Workflows** | 1 (ECM manager‚Üífield) | "Multi-agent orchestration works" |
| **Production Executions** | 1,250/day (ECM only) | "Already in production" |
| **Cost Optimization** | 85% savings ($141 vs $927) | "Smart routing pays for itself" |
| **Compliance Grade** | Regulatory audit-ready (FinCrime) | "Enterprise moat" |

---

## Revised Team Structure (5 People, 36 Hours)

| Track | Owner | Output | Priority |
|-------|-------|--------|----------|
| **T1: Platform Core** | Person A | Skill executor + OpenRouter gateway + skill registry | P0 (blocking) |
| **T2: Domain Onboarding** | Person B | Migrate 3 domains to platform (aspora.config.yaml for each) | P0 (blocking) |
| **T3: Multi-Agent Flow** | Person C | ECM manager‚Üífield workflow with dashboard | P0 (demo centerpiece) |
| **T4: Auto-Learning** | Person D | Feedback capture + test generation | P1 (moat demo) |
| **T5: Demo + Pitch** | **You** (User) | Slack integration + demo script + narrative | P0 (judging) |

---

## Hour-by-Hour Timeline (Revised)

### Hours 0-8: Platform Foundation (Parallel)

**T1 (Platform Core)** ‚Äî Person A
**Goal**: Build minimal platform runtime that can execute skills

```python
# packages/platform-runtime/executor.py
import yaml
from openai import OpenAI

class SkillExecutor:
    def __init__(self, registry_path: str, openrouter_key: str):
        self.registry = self._load_registry(registry_path)
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=openrouter_key
        )

    def _load_registry(self, path: str) -> dict:
        """Load skills from aspora.config.yaml files"""
        # Scan domains/ directory for aspora.config.yaml
        # Build skill_id ‚Üí config mapping
        return {}

    async def execute(self, skill_id: str, context: dict) -> dict:
        skill = self.registry[skill_id]

        # Load skill prompt from SKILL.md
        prompt = self._load_skill_prompt(skill)

        # Select model based on skill config
        model = skill.get('model', 'anthropic/claude-haiku-4.5')

        # Call OpenRouter
        start_time = time.time()
        response = await self.client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": context['input']}
            ]
        )

        latency = time.time() - start_time
        cost = self._calculate_cost(response.usage, model)

        # Track metrics
        await self._log_execution(skill_id, latency, cost, response)

        return {
            "skill": skill_id,
            "output": response.choices[0].message.content,
            "cost": cost,
            "latency": latency,
            "model": model
        }
```

**Checkpoint Hour 8**: Can execute 1 skill (testing with qa-agent from TRM domain)

---

**T2 (Domain Onboarding)** ‚Äî Person B
**Goal**: Create aspora.config.yaml for each domain

```yaml
# domains/fincrime/aspora.config.yaml
domain:
  name: fincrime
  description: Financial crime detection and investigation
  owner: compliance-team

skills:
  - name: detecting-fincrime-alerts
    path: ./SKILL.md
    model: anthropic/claude-sonnet-4.5  # Complex investigation
    cost_budget: 50  # $50/day max

    triggers:
      - type: cron
        schedule: "0 8 * * *"  # Daily 8am triage
      - type: command
        pattern: "investigate order {order_id}"

    resources:
      shared:
        - queries/*.sql
        - references/*.md
      blocked: []  # No RBAC for single-skill domain

    guardrails: ./GUARDRAILS.md
    decisions: ./DECISIONS.md
```

```yaml
# domains/fraud-guardian/aspora.config.yaml
domain:
  name: fraud-guardian
  description: Fraud rule analysis and optimization
  owner: fraud-ops-team

skills:
  - name: rule-simulation
    path: .claude/skills/rule-simulation.md
    model: anthropic/claude-haiku-4.5  # Fast simulation

  - name: rule-comparison
    path: .claude/skills/rule-comparison.md
    model: anthropic/claude-sonnet-4.5  # Complex comparison

  - name: rule-noise-analysis
    path: .claude/skills/rule-noise-analysis.md
    model: anthropic/claude-sonnet-4.5

  - name: qa-agent
    path: .claude/skills/qa-agent.md
    model: anthropic/claude-haiku-4.5  # Simple QA validation
```

```yaml
# domains/ecm/aspora.config.yaml
domain:
  name: ecm
  description: E-commerce order operations
  owner: operations-team

skills:
  # Manager skills (batch)
  - name: triage-and-assign
    path: manager/triage-and-assign/SKILL.md
    model: anthropic/claude-sonnet-4.5
    role: manager

    triggers:
      - type: cron
        schedule: "0 7,14,20 * * *"  # 3x daily

    resources:
      shared:
        - ../shared/queries/ecm-pending-list.sql
        - ../shared/config/stuck-reasons.yaml
      blocked:
        - ../shared/runbooks/**  # Manager NEVER loads runbooks
        - ../field/**

  # Field skills (interactive)
  - name: my-tickets
    path: field/my-tickets/SKILL.md
    model: anthropic/claude-haiku-4.5
    role: field

    triggers:
      - type: message
        pattern: "show my tickets"

    resources:
      shared:
        - ../shared/runbooks/**
        - ../shared/queries/ecm-order-detail-v2.sql
      blocked:
        - ../shared/queries/ecm-pending-list.sql  # Field NEVER triages
        - ../manager/**
```

**Checkpoint Hour 8**: 3 domain configs ready, skill paths validated

---

**T3 (Multi-Agent Flow)** ‚Äî Person C
**Goal**: Build ECM manager‚Üífield workflow

```python
# workflows/ecm_daily_triage.py
async def ecm_daily_triage_workflow(executor: SkillExecutor):
    """
    Multi-agent workflow:
    1. Manager triages stuck orders (1x)
    2. Field agents check their assignments (12x)
    """

    # Step 1: Manager triage (Sonnet, expensive but smart)
    print("ü§ñ Manager Agent: Triaging stuck orders...")
    triage_result = await executor.execute(
        skill_id="ecm/manager/triage-and-assign",
        context={
            "trigger": "cron",
            "input": "Load pending orders and assign to agents based on load balancing"
        }
    )

    print(f"   üìä Triaged {triage_result['orders_count']} orders")
    print(f"   üí∞ Cost: ${triage_result['cost']:.2f}")

    # Step 2: Write assignments to shared CSV (simulated)
    assignments = triage_result['data']['assignments']
    await write_csv("assignments.csv", assignments)

    # Step 3: Field agent checks tickets (Haiku, cheap and fast)
    print("\nüé´ Field Agent (Sarah): Checking my tickets...")
    tickets_result = await executor.execute(
        skill_id="ecm/field/my-tickets",
        context={
            "trigger": "message",
            "user": "sarah@aspora.com",
            "input": "show my tickets"
        }
    )

    print(f"   Found {tickets_result['data']['ticket_count']} tickets")
    print(f"   üí∞ Cost: ${tickets_result['cost']:.2f}")

    # Summary
    total_cost = triage_result['cost'] + tickets_result['cost']
    print(f"\nüí∞ Total Workflow Cost: ${total_cost:.2f}")
    print(f"   (Manager: Sonnet, Field: Haiku)")

    return {
        "workflow": "ecm_daily_triage",
        "total_cost": total_cost,
        "orders_triaged": triage_result['orders_count'],
        "field_tickets": tickets_result['data']['ticket_count']
    }
```

**Checkpoint Hour 8**: Workflow connects 2 skills (manager + field)

---

**T4 (Auto-Learning)** ‚Äî Person D
**Goal**: Capture user corrections and generate tests

```python
# packages/feedback/capture.py
async def capture_correction(
    execution_id: str,
    user_id: str,
    correction: str
) -> dict:
    """
    User clicks üëé on Slack message ‚Üí correction modal ‚Üí this function
    """

    # 1. Fetch original execution
    execution = await db.query(
        "SELECT skill_id, input, output FROM skill_executions WHERE id = ?",
        [execution_id]
    )

    # 2. Generate test case using GPT-4o mini (cheap)
    test_case = await generate_test_from_correction(
        skill_id=execution['skill_id'],
        input=execution['input'],
        expected_output=correction,
        actual_output=execution['output']
    )

    # 3. Save to tests/generated/{domain}/{skill}/
    test_path = f"tests/generated/{execution['skill_id']}/{test_case['id']}.yaml"
    await write_yaml(test_path, test_case)

    # 4. Update execution record
    await db.execute(
        "UPDATE skill_executions SET user_correction = ? WHERE id = ?",
        [correction, execution_id]
    )

    return {
        "test_id": test_case['id'],
        "test_path": test_path,
        "execution_id": execution_id
    }

async def generate_test_from_correction(
    skill_id: str,
    input: str,
    expected_output: str,
    actual_output: str
) -> dict:
    """Use GPT-4o mini to generate regression test"""

    prompt = f"""
You are creating a regression test for an AI skill.

Skill: {skill_id}
Input: {input}
Expected Output (user correction): {expected_output}
Actual Output (what agent said): {actual_output}

Generate a YAML test case in this format:

test_id: <uuid>
skill: {skill_id}
input: |
  {input}
expected_output: |
  {expected_output}
tags:
  - user_correction
  - regression
created_at: {datetime.now().isoformat()}
"""

    response = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    return yaml.safe_load(response.choices[0].message.content)
```

**Checkpoint Hour 8**: Can capture 1 correction, generate 1 test, save to file

---

**T5 (Demo + Pitch)** ‚Äî You
**Goal**: Slack integration + demo narrative

```typescript
// demo-bot.ts
import { App } from '@slack/bolt';

const app = new App({
  token: process.env.SLACK_BOT_TOKEN,
  signingSecret: process.env.SLACK_SIGNING_SECRET
});

// ECM Field Commands
app.message(/show my tickets/, async ({ message, say }) => {
  const result = await executor.execute({
    skill: "ecm/field/my-tickets",
    user: message.user
  });

  await say({
    text: `üé´ Your Queue ‚Äî ${result.data.ticket_count} tickets`,
    blocks: [
      {
        type: "section",
        text: { type: "mrkdwn", text: result.output }
      },
      {
        type: "context",
        elements: [
          { type: "mrkdwn", text: `üí∞ Cost: $${result.cost.toFixed(4)} | ‚ö° ${result.latency.toFixed(2)}s` }
        ]
      }
    ]
  });
});

app.message(/investigate order (.+)/, async ({ message, context, say }) => {
  const orderId = context.matches[1];

  const result = await executor.execute({
    skill: "fincrime/detecting-fincrime-alerts",
    context: { order_id: orderId }
  });

  await say({
    text: result.output,
    blocks: [
      {
        type: "section",
        text: { type: "mrkdwn", text: result.output }
      },
      {
        type: "actions",
        elements: [
          {
            type: "button",
            text: { type: "plain_text", text: "üëç Correct" },
            action_id: "feedback_positive"
          },
          {
            type: "button",
            text: { type: "plain_text", text: "üëé Incorrect" },
            action_id: "feedback_negative"
          }
        ]
      }
    ]
  });
});

// Fraud Guardian Commands
app.message(/simulate rule (.+)/, async ({ message, context, say }) => {
  const ruleFile = context.matches[1];

  await say("üîÑ Simulating fraud rule on historical data...");

  const result = await executor.execute({
    skill: "fraud-guardian/rule-simulation",
    context: { rule_file: ruleFile }
  });

  await say(result.output);
});

// Feedback Handler (THE MOAT)
app.action('feedback_negative', async ({ ack, body, client }) => {
  await ack();

  // Open modal for correction
  await client.views.open({
    trigger_id: body.trigger_id,
    view: {
      type: "modal",
      title: { type: "plain_text", text: "Provide Correction" },
      submit: { type: "plain_text", text: "Submit" },
      blocks: [
        {
          type: "input",
          block_id: "correction",
          label: { type: "plain_text", text: "What should the agent have said?" },
          element: {
            type: "plain_text_input",
            action_id: "correction_input",
            multiline: true
          }
        }
      ]
    }
  });
});

app.view('submit', async ({ ack, view, body }) => {
  await ack();

  const correction = view.state.values.correction.correction_input.value;

  // Capture correction + generate test
  const testResult = await captureCorrection({
    execution_id: body.message.ts,
    user_id: body.user.id,
    correction: correction
  });

  console.log(`‚úÖ Test generated: ${testResult.test_path}`);
});
```

**Checkpoint Hour 8**: Slack bot responds to 3 commands (ECM, FinCrime, Fraud)

---

### CHECKPOINT 1 (Hour 8): Integration Test

**ALL HANDS DEMO**:
1. Person A: Show `executor.execute("fraud-guardian/qa-agent")` works
2. Person B: Show all 3 domain configs load without errors
3. Person C: Show ECM workflow connects manager‚Üífield
4. Person D: Show correction capture generates 1 test file
5. You: Show Slack bot responds to "show my tickets"

**If ANY component broken**: Debug together for 1 hour (Hour 8-9)

---

### Hours 9-18: Core Demo Loop (Build the Centerpiece)

**FOCUS**: Make the multi-agent workflow + cost comparison + auto-learning perfect

**T1 + T2 + T3 (Combined)**: ECM Multi-Agent Workflow Polish
- Add real data (200 fake stuck orders in CSV)
- Manager skill triages ‚Üí outputs assignments
- Field skill reads assignments ‚Üí shows Sarah's tickets
- Dashboard shows:
  - Cost breakdown (Manager: $0.50 Sonnet, Field: $0.02 Haiku)
  - Model selection visualization
  - Skills executed (2/14 skills active)

**T4**: Test Suite Growth Demo
- Pre-seed 5 corrections
- Generate 5 tests automatically
- Show test runner: `aspora test ecm/field/my-tickets --generated`
- Live demo: User corrects ‚Üí test counter increments 5‚Üí6

**T5**: Slack UX Polish
- Rich formatting for ticket lists (P1 üî¥, P2 üü°, P3 üü¢)
- Loading states ("Investigating order... this may take 10s")
- Error handling (skill timeout ‚Üí fallback message)

**DEMO SCRIPT** (3 minutes):

```markdown
## Act 1: Multi-Domain Platform (30 sec)
"Most hackathons show you one chatbot. We built a platform with 3 production domains."

[Show directory structure:
  domains/
    ecm/           ‚Üê 9 skills
    fincrime/      ‚Üê 1 skill
    fraud-guardian/ ‚Üê 4 skills
]

"14 skills across compliance, operations, and fraud. All running on one platform."

## Act 2: Multi-Agent Orchestration (60 sec)
"Let me show you ECM Operations ‚Äî our stuck order resolution system."

[Terminal: python workflows/ecm_daily_triage.py]

ü§ñ Manager Agent: Triaging stuck orders...
   üìä Triaged 200 orders
   üí∞ Cost: $0.50 (Claude Sonnet 4.5)

üé´ Field Agent (Sarah): Checking my tickets...
   Found 8 tickets (3 P1, 5 P2)
   üí∞ Cost: $0.02 (Claude Haiku 4.5)

üí∞ Total Workflow Cost: $0.52

[Dashboard shows cost comparison]
   Without OpenRouter: $5.20 (all Sonnet)
   With OpenRouter: $0.52 (manager=Sonnet, field=Haiku)
   Savings: 90% per workflow

"OpenRouter auto-selects the right model for each task. Manager needs Sonnet for complex triage. Field agent uses Haiku for simple lookups. This is running in production ‚Äî 1,250 executions/day, $141/month vs $927 baseline."

## Act 3: The Moat ‚Äî Auto-Learning (60 sec)
[Slack demo]

User: "show my tickets"
Bot: [shows ticket list with runbook steps]

User: clicks üëé "Step 2 should be 'Check Lulu API logs' not 'Check LULU'"

[Code execution visible on screen]
‚úÖ Correction captured
‚úÖ Generating test case with GPT-4o mini...
‚úÖ Test saved: tests/generated/ecm/field/my-tickets/abc123.yaml

[Dashboard updates: Test Suite: 5 tests ‚Üí 6 tests]

"Every mistake becomes a regression test. After 6 months in production, we'll have 10,000 tests. A competitor starting today? Zero. That's a technical moat you can't buy."

## Act 4: Cross-Domain Power (30 sec)
"This isn't just ECM. Same platform runs financial crime investigations."

[Slack: "investigate order AE136ABC00"]

Bot: [shows TRM alert analysis]
"Alert: WATCHLIST_SCREENING_HIT + MONEY_LAUNDERING
Risk Score: 87/100 (Critical)
Recommendation: ESCALATE
Rationale: Multiple critical signals, new beneficiary, velocity spike"

üí∞ Cost: $0.35 (Claude Sonnet 4.5)

"Regulatory audit-grade investigation. 22 TRM rules in one skill."

## Closing (30 sec)
"Three production domains. Multi-agent orchestration. Auto-learning from every mistake. 85% cost reduction.

We're not building a chatbot. We're building the Shopify for AI agents ‚Äî a platform others build on.

Questions?"
```

**Checkpoint Hour 18**: Full demo runs end-to-end, 3-min pitch delivered

---

### Hours 18-24: Polish & Stretch Goals

**Decision Point (Hour 18)**: Are we on track?

**IF YES** (everything works):
- Add 4th domain visualization (shows "onboarding new skills is fast")
- Add canary deployment diagram (shadow mode for ECM manager skill)
- Add cost projection chart (6-month: $850 saved vs baseline)
- Polish Grafana dashboard (live metrics, 3 panels minimum)

**IF NO** (missing core pieces):
**CUT SCOPE IMMEDIATELY**:
1. ‚ùå Cut: 4th domain, canary deployment, Grafana dashboard
2. ‚ö†Ô∏è Simplify: Auto-learning (just show 1 correction, don't build test runner)
3. ‚úÖ Focus: Multi-agent workflow + cost comparison (non-negotiable)

**ALL HANDS (Hour 18-24)**:
- Record backup video (screen recording of full demo)
- Test on different WiFi network (backup phone hotspot)
- Print slide deck as PDF (backup if laptop dies)
- Prepare 2-minute version (if time limit strict)

---

### Hours 24-30: Rehearsal & Dataset Prep

**Rehearsal 1** (Hour 24): Run demo with timer
- Goal: < 3 minutes for full demo
- Fix: Any stumbles, long pauses, unclear explanations

**Dataset Prep** (Hour 25-27):
- Generate 200 fake stuck orders (CSV)
- Add 10 fake corrections to database
- Generate 10 tests from corrections
- Seed dashboard with 100 fake executions (show activity over time)

**Rehearsal 2** (Hour 28): External tester
- Find someone NOT on team
- Give them demo
- Ask: "What's confusing?" "What's the value prop?"
- Simplify based on feedback

**Rehearsal 3** (Hour 29): Timed with Q&A
- 3-min demo + 2-min Q&A simulation
- Practice answers to expected questions:
  - "What if OpenAI builds this?" ‚Üí "They won't. Cost optimization hurts their revenue. Our moat is the 10K test suite ‚Äî takes 6 months to build."
  - "How do you make money?" ‚Üí "Platform fees (20% markup on OpenRouter), enterprise hosting ($500/mo), marketplace revenue share (30%)"
  - "What's next?" ‚Üí "Onboard 3 more domains next month (Support, Retention, Ops). Each adds 5-10 skills."

---

### Hours 30-36: Final Prep & Presentation

**Hour 30-32**: Create backup slides (in case live demo fails)

```
Slide 1: The Hook
  "AI agents are expensive black boxes that repeat mistakes"

  [Photo of someone clicking 'retry' on ChatGPT]

Slide 2: The Problem (3 bullets)
  üí∏ Expensive ‚Äî GPT-4 calls add up ($927/month for one workflow)
  üß† Dumb ‚Äî agents repeat mistakes (no learning)
  üî• Fragile ‚Äî one bad prompt breaks everything

Slide 3: Our Solution
  "Aspora Platform ‚Äî Where AI agents get smarter and cheaper"

  3 Innovations:
  1Ô∏è‚É£ Smart Routing ‚Äî Haiku for easy tasks, Sonnet for hard ones (85% cost reduction)
  2Ô∏è‚É£ Auto-Learning ‚Äî Every correction becomes a regression test
  3Ô∏è‚É£ Multi-Agent ‚Äî Manager triages, field executes (production-proven pattern)

Slide 4: Live Demo
  [Screen recording or live terminal]

  Show:
  - Multi-agent workflow (manager ‚Üí field)
  - Cost comparison ($0.52 vs $5.20)
  - Correction ‚Üí test generation
  - Dashboard with 3 domains

Slide 5: The Moat (6-Month Projection)
  [Chart showing test suite growth over time]

  After 6 months:
  - 10,000+ regression tests (vs competitor's 0)
  - 3 production domains ‚Üí 6 domains
  - $850/month saved vs GPT-wrapper baseline

  "Technical moat you can't buy"

Slide 6: Traction
  "Already running in production"

  - 1,250 executions/day (ECM Operations)
  - 94% assignment accuracy
  - $141/month cost (vs $927 baseline)
  - Regulatory audit-grade (FinCrime domain)

Slide 7: Platform Vision
  "The Shopify for AI Agents"

  [Diagram: Platform Core ‚Üí Skill Marketplace ‚Üí Domains]

  We handle:
  - Skill execution
  - Model routing (OpenRouter)
  - Observability
  - Auto-learning

  You build:
  - Skills (YAML + Markdown)
  - Domain logic
  - Business value

Slide 8: Ask
  "We're building the platform where AI agents learn from every mistake"

  Next: Onboard 3 more domains (Support, Retention, Ops)
  By end of year: 50+ skills, $200K ARR from platform fees

  Questions?
```

**Hour 32-34**: Team Sleep Rotation
- **You + Person A**: Stay awake (final testing, bug fixes)
- **Person B, C, D**: Sleep 2 hours (need energy for demo delivery)
- **Hour 34**: Switch (You sleep, Person C monitors)

**Hour 34-36**: Final Checks (ALL HANDS)

**Pre-Demo Checklist** (print this, check boxes):
- [ ] All laptops fully charged + backup charger
- [ ] WiFi tested in demo area (measure speed: > 10 Mbps)
- [ ] Backup video downloaded locally (not cloud)
- [ ] Slide deck on 2 devices (laptop + tablet/phone)
- [ ] OpenRouter API key funded ($50 balance)
- [ ] Slack workspace configured, bot running
- [ ] Database seeded (200 orders, 10 corrections, 100 executions)
- [ ] Terminal windows pre-configured (workflow script ready to run)
- [ ] Phone silenced, notifications off
- [ ] Team knows who speaks when (assign 3-min demo to 1 person)
- [ ] Q&A roles assigned (Person A: tech questions, You: business questions)

**Demo Dry Run** (Hour 35):
- Full 3-min demo in demo area
- Check projector visibility
- Adjust font sizes if needed
- Test microphone (if provided)

**Final Brief** (Hour 36):
- Review answers to expected questions
- Assign fallback plan (if demo crashes, Person B starts backup video while Person A debugs)
- Deep breath, confidence check

---

## Risk Mitigation Matrix

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Skill loading fails** | Medium | High | Pre-test all 14 skills, cache loaded configs in memory |
| **OpenRouter API rate limit** | Low | High | Use personal API key as fallback, fund with $50 |
| **Multi-agent workflow breaks** | Medium | Critical | Have backup: show single-skill execution + explain workflow on slides |
| **WiFi dies during demo** | High | Critical | **PRIMARY MITIGATION**: Backup video pre-recorded, download locally |
| **Laptop crashes** | Low | Critical | 2 laptops ready, demo runs on both beforehand |
| **Slack bot goes offline** | Medium | Medium | Have CLI version ready (`aspora chat ecm/field/my-tickets`) |
| **Test generation too slow** | Medium | Low | Pre-generate 10 tests, show increment from 10‚Üí11 live |
| **Dashboard doesn't load** | High | Low | Screenshots of dashboard pre-loaded in slide deck |
| **Judges don't understand multi-agent** | Medium | Medium | Use metaphor: "Like Uber ‚Äî dispatcher assigns rides, drivers execute them" |
| **Cost savings seem small** | Low | Medium | Multiply by 10 companies: "$850/mo √ó 10 companies = $8,500/mo = $102K/year saved" |

---

## Success Criteria

### Minimum Viable Demo (Must Achieve)
- ‚úÖ Platform loads all 14 skills from 3 domains
- ‚úÖ Multi-agent workflow executes (ECM manager ‚Üí field)
- ‚úÖ Cost comparison shown ($0.52 vs $5.20)
- ‚úÖ User correction captured + test generated
- ‚úÖ Pitch delivered in < 3 minutes

### Stretch Goals (Nice to Have)
- üéØ Live Slack integration (not just CLI)
- üéØ Grafana dashboard with 3 panels
- üéØ 10+ tests in test suite (show growth)
- üéØ 4 domain onboarding (add one more domain during demo)

### Gold Standard (Win the Hackathon)
- üèÜ Judges say "This could be a real company"
- üèÜ Someone asks "Can I use this?" or "When can I sign up?"
- üèÜ Cost moat resonates (they write down $850/month saved)
- üèÜ Multi-domain story clicks ("Platform, not just chatbot")
- üèÜ Auto-learning moat gets questions ("How big is your test suite after 6 months?")

---

## Why This Wins

### Depth Over Breadth
**Competitors**: Build 1 demo chatbot from scratch
**Us**: Integrate 3 REAL production domains (14 skills)

**Judge Impact**: "This team has been building for months ‚Äî this is production-ready, not a weekend hack"

### Platform Story
**Competitors**: "We built an AI assistant for X"
**Us**: "We built a platform where multiple teams independently onboard skills"

**Judge Impact**: "This is venture-scale ‚Äî marketplace model, not single-purpose tool"

### Production Proof
**Competitors**: Fake data, toy examples
**Us**: "1,250 executions/day, already running at Aspora Remittance since Feb 2026"

**Judge Impact**: "Real traction, not just a hackathon project"

### Technical Moat
**Competitors**: No differentiation (everyone uses GPT wrappers)
**Us**: Auto-learning feedback loop ‚Üí 10,000 tests after 6 months

**Judge Impact**: "Sustainable competitive advantage ‚Äî can't be copied easily"

### Cost Story
**Competitors**: No cost awareness (burn $5K/month on API calls)
**Us**: OpenRouter smart routing ‚Üí 85% reduction ($141 vs $927)

**Judge Impact**: "This team thinks about unit economics ‚Äî investor-ready"

---

## Post-Demo Q&A Prep

### Expected Questions & Answers

**Q: What's your moat?**
A: "Three layers:
1. Auto-learning ‚Äî every correction becomes a regression test. After 6 months: 10,000 tests vs competitor's 0.
2. Multi-domain network effects ‚Äî each new domain adds skills that other domains can reuse (e.g., triage pattern works for ECM, FinCrime, Support).
3. Cost optimization data ‚Äî we know which models work for which tasks. Took 6 months of production data to learn Haiku works for 80% of operations tasks."

**Q: What if OpenAI builds this?**
A: "They won't. Three reasons:
1. Cost optimization hurts their revenue ‚Äî why would they tell you to use Haiku instead of GPT-4?
2. Our moat is domain-specific test suites ‚Äî they can't build 10K tests for ECM operations or fraud rules.
3. OpenRouter gives us provider diversity ‚Äî if Anthropic goes down, we fallback to GPT-4o. OpenAI can't offer that."

**Q: How do you make money?**
A: "Platform business model:
1. **Platform fees**: 20% markup on OpenRouter costs (embedded billing). If customer uses $100 in LLM calls, they pay us $120.
2. **Enterprise hosting**: $500/month for private deployment with custom RBAC + compliance features.
3. **Skill marketplace**: 30% revenue share on third-party skills (like Shopify app store)."

**Q: What's next?**
A: "Four-phase growth:
1. **Month 1-2**: Onboard 3 more Aspora domains (Support, Retention, Ops) ‚Äî get to 25+ skills
2. **Month 3-4**: Open platform to external teams (beta partners with custom domains)
3. **Month 5-6**: Launch skill marketplace (third-party skill developers)
4. **Month 7-12**: Enterprise sales (multi-tenant platform for large fintechs)"

**Q: How is this different from LangChain/LlamaIndex?**
A: "LangChain is a developer framework ‚Äî it's low-level primitives for building agents.
Aspora is a platform ‚Äî teams onboard skills without writing code.

Analogy:
- LangChain = React (developer builds UI)
- Aspora = Shopify (merchant uploads products, platform handles everything)

Target user:
- LangChain: ML engineers
- Aspora: Domain experts (fraud analysts, operations managers)"

**Q: What about hallucinations?**
A: "Three-layer defense:
1. **Structured outputs** ‚Äî skills return JSON/YAML, not freeform text. Harder to hallucinate when format is constrained.
2. **Test suite** ‚Äî 10K+ regression tests catch hallucinations before production.
3. **Human-in-loop** ‚Äî Critical decisions (ECM escalations, fraud rejections) require senior review."

**Q: How do you ensure security?**
A: "Multi-layer isolation:
1. **RBAC** ‚Äî manager skills can't access runbooks, field skills can't access triage queries (role-based blocking)
2. **Namespace separation** ‚Äî domains run in isolated K8s namespaces
3. **gVisor sandbox** ‚Äî kernel-level isolation for skill execution (Google Agent Sandbox pattern)
4. **Audit trail** ‚Äî every resource access logged to PostgreSQL"

**Q: Can I use this for my company?**
A: "Not yet ‚Äî we're in private beta with Aspora's internal domains.

But we're launching public beta in April 2026. Leave your email and we'll send you early access.

What domain would you want to onboard first?" [flip question to learn about their use case]

---

## Final Motivation

You have **3 production domains already built**. ECM Operations is running 1,250 executions/day. FinCrime investigations are regulatory audit-ready. Fraud Guardian has 4 analysis skills.

**You're not building a demo. You're integrating real systems.**

This is the hackathon equivalent of showing up to a race with a Formula 1 car while everyone else is assembling go-karts from spare parts.

**The judges will feel this depth.** When you show 14 skills across 3 domains, they'll know this isn't a weekend project ‚Äî it's a platform.

**GO WIN THIS.** üèÜ

---

## Appendix: File Structure After Hackathon

```
aspora-platform/
‚îú‚îÄ‚îÄ domains/
‚îÇ   ‚îú‚îÄ‚îÄ ecm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aspora.config.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ triage-and-assign/SKILL.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ escalate-stuck-orders/SKILL.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ field/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ my-tickets/SKILL.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ order-details/SKILL.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shared/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ queries/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ runbooks/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ fincrime/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aspora.config.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SKILL.md (detecting-fincrime-alerts)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ queries/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ references/
‚îÇ   ‚îî‚îÄ‚îÄ fraud-guardian/
‚îÇ       ‚îú‚îÄ‚îÄ aspora.config.yaml
‚îÇ       ‚îú‚îÄ‚îÄ .claude/skills/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ rule-simulation.md
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ rule-comparison.md
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ rule-noise-analysis.md
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ qa-agent.md
‚îÇ       ‚îî‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ platform-runtime/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ registry.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openrouter_client.py
‚îÇ   ‚îî‚îÄ‚îÄ feedback/
‚îÇ       ‚îú‚îÄ‚îÄ capture.py
‚îÇ       ‚îî‚îÄ‚îÄ test_generator.py
‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îî‚îÄ‚îÄ ecm_daily_triage.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ generated/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ecm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fincrime/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fraud-guardian/
‚îÇ   ‚îî‚îÄ‚îÄ manual/
‚îú‚îÄ‚îÄ demo-bot.ts (Slack integration)
‚îú‚îÄ‚îÄ docker-compose.yml (PostgreSQL + Grafana)
‚îî‚îÄ‚îÄ README.md
```

**Size**: ~50 files, 3,000 lines of code (counting existing skills: 14 √ó 200 lines avg)

**This is shippable.** After the hackathon, this becomes your production platform.
